[default]

foo                               = the most ubiquitous variable name after 'i' and 'j' in programming

app_verbose                       = Verbosity flag for flask app. Options are True or False, defaults to False.
app_debug                         = Debugging flag for flask app. Options are True or False, defaults to False.
app_silent                        = Silent flag for flask app. Options are True or False, defaults to False.
app_timezone                      = Timezone for application timestamps. Uses IANA timezone names (e.g., America/New_York for East Coast US, America/Los_Angeles for West Coast, UTC for universal time). Defaults to America/New_York. Automatically handles daylight saving time transitions.

stt_device_id                     = Device ID for STT model.  Options are 'cuda:0', 'cuda:1' or 'cpu', defaults to 'cuda:0'.
stt_model_id                      = Model ID for STT model.  Options are currently only 'distil-whisper/distil-large-v2', defaults to 'distil-whisper/distil-large-v2'.

embedding model name              = OpenAI embedding model to use for generating text embeddings. Options are 'text-embedding-ada-002', 'text-embedding-3-small', 'text-embedding-3-large'. Required for similarity search functionality.

spacy model name                  = spaCy language model to use for text normalization in the Normalizer module. Options include 'en_core_web_sm' (small/fast), 'en_core_web_md' (medium), 'en_core_web_lg' (large/accurate). Default is 'en_core_web_sm'. Must be installed via: python -m spacy download <model_name>

expand symbols to words           = Boolean flag to control symbol-to-word expansion in embedding normalization. When True, converts symbols and numbers to words (e.g., '@' → 'at sign', '123' → 'one two three'). When False, preserves symbols after gist extraction. Default is False. Useful for preventing expansion on short queries.

async embedding generation        = Boolean flag to control whether embedding generation runs asynchronously in insert_io_row method. When True, the method returns immediately while embeddings are generated in background threads. When False, the method waits for embeddings to complete before returning. Default is True for better responsiveness.

debug text truncation length      = Integer value controlling how many characters of text to show in debug output before truncating with '...'. Used in debug messages for input/output text display. Default is 48 characters. Higher values show more text but may clutter console output.

tts_local_url_template            = URL string used to build arequest for the local TTS service
tts_generation_strategy           = Strategy for generating TTS audio.  Options are 'local' and 'openai', defaults to local.

app_config_server_name            = Name of the server that hosts the flask app.  Needed for CORS workaround.

path_to_snapshots_dir_wo_root     = Path to the snapshots directory, relative to the root of the project.
path_to_events_df_wo_root         = Path to the events dataframe, relative to the root of the project.

path_to_prompt_generator_data_function_mapping_wo_root = Path to the data for function mapping file, relative to the root of the project. Two possible extension types: *.txt indicates raw question, *.xml indicates questions plus XML response object

;vox_command_llm_name              = Name of the LLM to use for the vox command.  Options are 'Mistral-7B-Instruct-v0.2/merged-00-2024.01.23.awq', defaults to 'Mistral-7B-Instruct-v0.2/merged-00-2024.01.23.awq'.
;vox_command_llm_path_wo_root      = Where in the project tree can we find the vox command LLM?
;vox_command_llm_device_map        = Which CUDA device should we assign the vox command LLM to?
;vox_command_prompt_path_wo_root   = Where does the command prompt template live?

router_and_vox_command_llm_name              = The user-friendly name assigned to the model ID
router_and_vox_command_url                   = The network path to the completion endpoint, e.g.: http://192.168.1.21:3000/v1/completions
router_and_vox_command_is_completion         = Is this a completion type call or not? Default to false for most models?
router_and_vox_command_model                 = LLM model ID used to identify the LORA trained model, e.g.: 'Deepily//convoluted/path/to/model'
router_and_vox_command_prompt_path_wo_root   = Path to the agent router and vox command prompt template

deepily_inference_chat_url            = Fully qualified path to the codegen LLM server, including port, e.g. 'http://127.0.0.1:3000'
tgi_server_codegen_name           = Name of the codegen LLM to use, e.g. 'Phind-CodeLlama-34B-v2'

tgi_server_router_name            = Name of the router LLM to use, e.g. 'Mistral-7B-Router-v0.2/merged-00-2024.02.05.awq'

# Prompt template paths for agent routing commands
prompt template for agent router go to date and time    = Path to the date and time agent prompt template file
prompt template for agent router go to math             = Path to the math agent prompt template file
prompt template for agent router go to calendar         = Path to the calendaring agent prompt template file
prompt template for agent router go to weather          = Path to the weather agent prompt template file
prompt template for agent router go to todo list        = Path to the todo list agent prompt template file
prompt template for agent router go to receptionist     = Path to the receptionist agent prompt template file
prompt template for agent router go to debugger         = Path to the debugger agent prompt template file
prompt template for agent router go to bug injector     = Path to the bug injector agent prompt template file
prompt template for agent router go to function mapping = Path to the function mapping agent prompt template file
prompt template for agent router go to math refactoring = Path to the math refactoring agent prompt template file

# Model specifications for agent routing commands
llm spec key for agent router go to date and time    = LLM model identifier to use for date and time agent
llm spec key for agent router go to math             = LLM model identifier to use for math agent
llm spec key for agent router go to calendar         = LLM model identifier to use for calendaring agent
llm spec key for agent router go to weather          = LLM model identifier to use for weather agent
llm spec key for agent router go to todo list        = LLM model identifier to use for todo list agent
llm spec key for agent router go to receptionist     = LLM model identifier to use for receptionist agent
llm spec key for agent router go to debugger         = LLM model identifier to use for debugger agent
llm spec key for agent router go to bug injector     = LLM model identifier to use for bug injector agent
llm spec key for agent router go to function mapping = LLM model identifier to use for function mapping agent
llm spec key for agent router go to math refactoring = LLM model identifier to use for math refactoring agent

# Serialization topics for agent routing commands
serialization topic for agent router go to date and time    = Topic identifier used when serializing date and time agent state
serialization topic for agent router go to math             = Topic identifier used when serializing math agent state
serialization topic for agent router go to calendar         = Topic identifier used when serializing calendaring agent state
serialization topic for agent router go to weather          = Topic identifier used when serializing weather agent state
serialization topic for agent router go to todo list        = Topic identifier used when serializing todo list agent state
serialization topic for agent router go to receptionist     = Topic identifier used when serializing receptionist agent state
serialization topic for agent router go to debugger         = Topic identifier used when serializing debugger agent state
serialization topic for agent router go to bug injector     = Topic identifier used when serializing bug injector agent state
serialization topic for agent router go to function mapping = Topic identifier used when serializing function mapping agent state
serialization topic for agent router go to refactoring      = Topic identifier used when serializing refactoring agent state

# Formatter template paths for agent routing commands
formatter template for agent router go to date and time     = Path to the date and time formatter template file
formatter template for agent router go to math              = Path to the math formatter template file
formatter template for agent router go to calendar          = Path to the calendaring formatter template file
formatter template for agent router go to weather           = Path to the weather formatter template file
formatter template for agent router go to todo list         = Path to the todo list formatter template file
formatter template for agent router go to receptionist      = Path to the receptionist formatter template file

# Formatter model specifications for agent routing commands
formatter llm spec for agent router go to date and time     = LLM model identifier to use for date and time formatter
formatter llm spec for agent router go to math              = LLM model identifier to use for math formatter
formatter llm spec for agent router go to calendar          = LLM model identifier to use for calendaring formatter
formatter llm spec for agent router go to weather           = LLM model identifier to use for weather formatter
formatter llm spec for agent router go to todo list         = LLM model identifier to use for todo list formatter
formatter llm spec for agent router go to receptionist      = LLM model identifier to use for receptionist formatter

##################################
# Agent Configuration
##################################

agent_function_mapping_tools_path_wo_root = Path to the XML file containing tool definitions for function mapping agents
agent_model_name_for_bug_injector        = LLM model identifier for the bug injector agent
agent_model_name_for_calendaring         = LLM model identifier for the calendaring agent
agent_model_name_for_date_and_time       = LLM model identifier for the date and time agent
agent_model_name_for_debugger            = LLM model identifier for the code debugger agent
agent_model_name_for_function_mapping    = LLM model identifier for the function mapping agent
agent_model_name_for_math                = LLM model identifier for the math agent
agent_model_name_for_math_refactoring    = LLM model identifier for the math refactoring agent
agent_model_name_for_receptionist        = LLM model identifier for the receptionist agent
agent_model_name_for_todo_list           = LLM model identifier for the todo list agent
agent_model_name_for_weather             = LLM model identifier for the weather agent

agent_prompt_for_bug_injector            = Path to the bug injector agent prompt template
agent_prompt_for_calendaring             = Path to the calendaring agent prompt template
agent_prompt_for_date_and_time           = Path to the date and time agent prompt template
agent_prompt_for_debugger                = Path to the debugger agent prompt template
agent_prompt_for_debugger_minimalist     = Path to the minimalist debugger agent prompt template (simplified version)
agent_prompt_for_function_mapping        = Path to the function mapping agent prompt template
agent_prompt_for_math                    = Path to the math agent prompt template
agent_prompt_for_math_refactoring        = Path to the math refactoring agent prompt template
agent_prompt_for_receptionist            = Path to the receptionist agent prompt template
agent_prompt_for_todo_list               = Path to the todo list agent prompt template
agent_prompt_for_weather                 = Path to the weather agent prompt template

agent_receptionist_serialize_prompt_to_json = Whether to serialize receptionist agent prompts to JSON format
agent_router_prompt_path_wo_root            = Path to the agent router prompt template
agent_todo_list_serialize_code_to_json      = Whether to serialize todo list agent code to JSON format
agent_todo_list_serialize_prompt_to_json    = Whether to serialize todo list agent prompts to JSON format

##################################
# General Configuration
##################################

auto_debug                               = Whether to automatically enable debugging when errors occur
code_execution_file_path                 = Path to the temporary file used for executing generated code
database_path_wo_root                    = Path to the LanceDB database for long-term memory storage

##################################
# LLM Model Configuration
##################################

deepily/ministral_8b_2410_ft_lora        = Connection string for the Deepily fine-tuned Ministral 8B model
deepily/ministral_8b_2410_ft_lora_params = Configuration parameters for the Deepily fine-tuned Ministral 8B model
kaitchup/phi_4_14b                       = Connection string for the Kaitchup Phi-4 14B model
kaitchup/phi_4_14b_params                = Configuration parameters for the Kaitchup Phi-4 14B model
mistralai/Ministral-8B-Instruct-2410     = Connection string for the MistralAI Ministral 8B Instruct model
mistralai/Ministral-8B-Instruct-2410_params = Configuration parameters for the MistralAI Ministral 8B Instruct model

##################################
# Formatter Configuration
##################################

formatter_model_name_for_calendaring     = LLM model identifier for formatting calendaring output
formatter_model_name_for_date_and_time   = LLM model identifier for formatting date and time output
formatter_model_name_for_math            = LLM model identifier for formatting math output
formatter_model_name_for_receptionist    = LLM model identifier for formatting receptionist output
formatter_model_name_for_todo_list       = LLM model identifier for formatting todo list output
formatter_model_name_for_weather         = LLM model identifier for formatting weather output

formatter_prompt_for_calendaring         = Path to the calendaring formatter prompt template
formatter_prompt_for_date_and_time       = Path to the date and time formatter prompt template
formatter_prompt_for_math                = Path to the math formatter prompt template
formatter_prompt_for_math_terse          = Whether to use terse formatting for math output (True/False)
formatter_prompt_for_receptionist        = Path to the receptionist formatter prompt template
formatter_prompt_for_todo_list           = Path to the todo list formatter prompt template
formatter_prompt_for_weather             = Path to the weather formatter prompt template

##################################
# Config Inheritance
##################################

inherits                                 = Name of the configuration section to inherit settings from

##################################
# Bug Injection
##################################

inject_bugs                              = Whether to inject bugs for testing the debugger agent (True/False)

##################################
# LLM Debugger Configuration
##################################

llm_debugger_params_google_gemini_pro    = Configuration parameters for Google Gemini Pro debugger
llm_debugger_params_groq_llama2_70b      = Configuration parameters for Groq Llama2 70B debugger
llm_debugger_params_groq_mixtral_8x78    = Configuration parameters for Groq Mixtral 8x78 debugger
llm_debugger_params_openai_gpt_3_5       = Configuration parameters for OpenAI GPT-3.5 debugger
llm_debugger_params_openai_gpt_4         = Configuration parameters for OpenAI GPT-4 debugger
llm_debugger_params_phi_4_14b            = Configuration parameters for Phi-4 14B debugger
llm_model_keys_for_debugger              = List of LLM model keys to use for the debugger agent

##################################
# Path Configuration
##################################

path_to_debugger_prompts_wo_root         = Path to directory containing debugger prompt templates
path_to_event_prompts_wo_root            = Path to directory containing event-related prompt templates
path_to_search_function_mapping_data_wo_root = Path to the function mapping synthetic data file
path_to_todolist_df_wo_root              = Path to the todo list dataframe CSV file
path_to_todolist_prompts_wo_root         = Path to directory containing todo list prompt templates

##################################
# Prompt Format Configuration
##################################

prompt_format_default                    = Default prompt format to use across all models
prompt_format_default_anthropic          = Default prompt format for Anthropic models
prompt_format_default_groq               = Default prompt format for Groq models
prompt_format_default_llama              = Default prompt format for Llama models
prompt_format_default_mistral            = Default prompt format for Mistral models
prompt_format_default_openai             = Default prompt format for OpenAI models
prompt_format_default_phi                = Default prompt format for Phi models
prompt_format_groq_llama_3_1_8b          = Specific prompt format for Groq Llama 3.1 8B
prompt_format_llm_deepily_ministral_8b_2410 = Specific prompt format for Deepily Ministral 8B
prompt_format_llm_deepily_phi_4_14b      = Specific prompt format for Deepily Phi-4 14B
prompt_format_template_directory         = Directory containing prompt format templates

##################################
# Additional Configuration
##################################

prompt template for confirmation dialog  = Path to the yes/no confirmation dialog prompt template
similarity_threshold_confirmation        = Similarity threshold for confirmation matching (0-100)
similarity_threshold_question            = Similarity threshold for question matching (0-100)
similarity_threshold_question_gist       = Similarity threshold for question gist matching (0-100)
vox_command_prompt_path_wo_root          = Path to the voice command prompt template file