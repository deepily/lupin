{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e1cb6b45aa3fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:13:07.095750Z",
     "start_time": "2024-10-06T17:13:07.088179Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825751caa807aa61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:13:50.483789Z",
     "start_time": "2024-10-06T17:13:50.478523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/model/src/ephemera/notebooks/cosa\n",
      "/var/model/src\n"
     ]
    }
   ],
   "source": [
    "print( os.getcwd() )\n",
    "os.chdir( \"/var/model/src/\" )\n",
    "print( os.getcwd() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f8782eb5a36e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:15:02.280674Z",
     "start_time": "2024-10-06T17:15:01.842274Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdu\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01magents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m  Llm\n",
      "File \u001B[0;32m/var/model/src/lib/agents/llm.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mopenai\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerativeai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m       \u001B[38;5;28;01mimport\u001B[39;00m HarmBlockThreshold\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerativelanguage_v1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HarmCategory\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m            \u001B[38;5;28;01mimport\u001B[39;00m InferenceClient\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.generativeai'"
     ]
    }
   ],
   "source": [
    "import lib.utils as du\n",
    "from lib.agents.llm import  Llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "        \"if I have six eggs, and my friend has six eggs, when we put them all in one basket, how many eggs do we have?\",\n",
    "        'Yo, einstein! How many times does the letter \"R\" occur in the word \"strawberry\"',\n",
    "        'Yo, Einstein! How many lowercase \"R\"s are in the word \"strawberry\"?',\n",
    "        \"What's the square root of 145?\",\n",
    "        \"What's worth more: 100 pennies or three quarters?\",\n",
    "        \"Which number is larger, 9.9 or 9.11?\",\n",
    "        \"What is 2+5+4+5-12+7-5?\",\n",
    "        \"If a train travels 60 miles in 1.5 hours, how far will it travel in 2 hours?\",\n",
    "        \"Calculate the answer: 241 - (-241) + 1\",\n",
    "        \"Count the number of occurrences of the letter 'L' in the word - ’LOLLAPALOOZA’.\",\n",
    "        \"Which weighs more, a pound of water, two pounds of bricks, a pound of feathers, or three pounds of air?\",\n",
    "    ]\n",
    "    ground_truth = [\n",
    "        \"12\",\n",
    "        \"3\",\n",
    "        \"3\",\n",
    "        \"12.041594578792296\",\n",
    "        \"100\",\n",
    "        \"9.9\",\n",
    "        \"6\",\n",
    "        \"80.0\",\n",
    "        \"483\",\n",
    "        \"4\",\n",
    "        \"air\"\n",
    "    ]\n",
    "    \n",
    "    responses_1st = []\n",
    "    responses_2nd = []\n",
    "    \n",
    "    assert len( questions ) == len( ground_truth ), (\n",
    "        f\"Length mismatch: questions({len( questions )}), \"\n",
    "        f\"ground_truth({len( ground_truth )}), \"\n",
    "    )\n",
    "    outer_timer   = Stopwatch()\n",
    "    debug   = False\n",
    "    verbose = False\n",
    "    \n",
    "    for question in questions:\n",
    "        \n",
    "        du.print_banner( f\"Question: {question}\" )\n",
    "        timer = Stopwatch()\n",
    "        agent  = MathAgent( question=SolutionSnapshot.remove_non_alphanumerics( question ), last_question_asked=question, routing_command=\"agent router go to math\", debug=False, verbose=False )\n",
    "        answer = agent.do_all()\n",
    "        responses_1st.append( answer )\n",
    "        timer.print( f\"Math agent answered: {answer}\", use_millis=True )\n",
    "        \n",
    "        timer = Stopwatch()\n",
    "        answer = \"Unable to answer due to a rate(?) error\"\n",
    "        try:\n",
    "            prompt_template = du.get_file_as_string( du.get_project_root() + \"/src/conf/prompts/agents/plain-vanilla-question.txt\" )\n",
    "            prompt = prompt_template.format( question=question )\n",
    "            model = Llm.GOOGLE_GEMINI_PRO\n",
    "            llm = Llm( model=model, debug=debug, verbose=verbose, default_url=\"WTF?!?\" )\n",
    "            results = llm.query_llm( prompt=prompt )\n",
    "            answer = dux.get_value_by_xml_tag_name( results, \"answer\" ).strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            if debug:\n",
    "                du.print_stack_trace( e, explanation=model, caller=\"Plain vanilla llm prompt\", prepend_nl=True )\n",
    "        finally:\n",
    "            responses_2nd.append( answer )\n",
    "        \n",
    "        timer.print( f\"LLM answered: {answer}\", use_millis=True )\n",
    "        \n",
    "        time.sleep( 10 )\n",
    "        \n",
    "    outer_timer.print( \"All questions answered\" )\n",
    "    \n",
    "    for i in range( len( questions ) ):\n",
    "        du.print_banner( f\"Question: {questions[i]}\" )\n",
    "        print( f\"Ground truth: [{ground_truth[i]}]\" )\n",
    "        print( f\"  Math agent: [{responses_1st[i]}]\" )\n",
    "        print( f\"      Gemini: [{responses_2nd[i]}]\" )\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
